{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b89326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "from numpy import asarray\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd243a2",
   "metadata": {},
   "source": [
    "##### 0, Define the hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae4b874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TODO: change hyper parameters\"\n",
    "n_epochs = 100\n",
    "batch_size_train = 128\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.001\n",
    "momentum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f27185",
   "metadata": {},
   "source": [
    "##### 1, Loading training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6180495f-e74a-447f-97b7-c621e7f40919",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR ='training'\n",
    "TEST_DIR ='testing_toy'\n",
    "TRAIN_LABEL = 'training/labels.txt'\n",
    "TEST_LABEL = 'testing_toy/labels.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de967eba",
   "metadata": {},
   "source": [
    "#### 1.1 load data from google drive, If you use the data from google drive, you need to define a torch.utils.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d9245a-dc2a-446c-a927-79d7267b9eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train_x, train_yimport os\n",
    "# step 1: load image to numpy array\n",
    "import os\n",
    "import numpy\n",
    "data_list = os.listdir(TRAIN_DIR)\n",
    "#print(data_list)\n",
    "\n",
    "def read_image(name):\n",
    "    # use PIL to load '.png' format, the output should be numpy array\n",
    "    data=[]\n",
    "    if name.endswith(\".png\"):\n",
    "        image=Image.open(os.path.join(TRAIN_DIR, name))#.convert('RGB')\n",
    "        #gray_image = ImageOps.grayscale(image)\n",
    "        data = asarray(image)\n",
    "        #print(data.shape)\n",
    "\n",
    "        #print('datashape', data.shape)\n",
    "        #print(data)\n",
    "    return data\n",
    "\n",
    "# make a dictionary, read from labels.txt\n",
    "def label_dict(name):\n",
    "    d = {}\n",
    "    with open(name,'r') as f:\n",
    "        for line in f.readlines():\n",
    "            lst = line.split()\n",
    "            \n",
    "            lst[1] = int(lst[1])\n",
    "            d[lst[0]] = lst[1]\n",
    "    return d\n",
    "\n",
    "# label_dict = {'0267.png': 4, '0267.png':5}\n",
    "\n",
    "train_x, train_y = [], []\n",
    "labelList = label_dict(TRAIN_LABEL)\n",
    "for name in data_list:\n",
    "    if name.endswith(\".png\"):\n",
    "        #print(name)\n",
    "        image = read_image(name) \n",
    "        #print(image)\n",
    "        # shape should be (num_channels, H, W)\n",
    "        label = labelList[name]\n",
    "        #print(image)\n",
    "        #print(label)\n",
    "        train_x.append(image)\n",
    "        train_y.append(label)\n",
    "\n",
    "train_x = numpy.stack(train_x) # (N, num_channels, H, W)\n",
    "train_y = numpy.stack(train_y)\n",
    "\n",
    "#print(train_x.mean())\n",
    "# print(np.std(train_x)\n",
    "#print(len(train_x.shape))\n",
    "# assert len(train_x.shape) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a3067b-2d64-4ddf-9ebe-5ae417f2bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list_test = os.listdir(TEST_DIR)\n",
    "#print(data_list)\n",
    "\n",
    "def read_image_test(name):\n",
    "    # use PIL to load '.png' format, the output should be numpy array\n",
    "    data=[]\n",
    "    if name.endswith(\".png\"):\n",
    "        image=Image.open(os.path.join(TEST_DIR, name))#.convert('RGB')\n",
    "        #gray_image = ImageOps.grayscale(image)\n",
    "        data = asarray(image)\n",
    "        #print('datashape', data.shape)\n",
    "        #print(data)\n",
    "    return data\n",
    "\n",
    "test_x, test_y = [], []\n",
    "labelList = label_dict(TEST_LABEL)\n",
    "for name in data_list_test:\n",
    "    if name.endswith(\".png\"):\n",
    "        #print(name)\n",
    "        image = read_image_test(name) \n",
    "        #print(image)\n",
    "        # shape should be (num_channels, H, W)\n",
    "        label = labelList[name]\n",
    "        #print(image)\n",
    "        #print(label)\n",
    "        test_x.append(image)\n",
    "        test_y.append(label)\n",
    "\n",
    "test_x = numpy.stack(test_x) # (N, num_channels, H, W)\n",
    "test_y = numpy.stack(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e666f07-e194-4f14-904b-1e84c2bd5f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train = train_x.mean()\n",
    "std_train = (np.std(train_y))\n",
    "\n",
    "mean_test = test_x.mean()\n",
    "std_test = (np.std(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5f058b2-c9c5-40e9-9c49-6a9895bb8895",
   "metadata": {},
   "outputs": [],
   "source": [
    "                           \n",
    "class EquationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x, y, transform=None):\n",
    "        ### x.shape = (N, num_channels, H, W)\n",
    "        ### y.shape = (N)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        #mean = statistics.mean(x), std = np.std(y)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # apply transformer: ToTensor and Normalize\n",
    "        img = self.x[idx]\n",
    "        # print(img.shape)\n",
    "        if self.transform != None:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        # convert numpy to torch tensor\n",
    "        # normalize to [0, 1]\n",
    "            \n",
    "        label = self.y[idx]-1\n",
    "        return (img, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8c4a3",
   "metadata": {},
   "source": [
    "#### 1.2 Now lets load data from torchvision instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d1ab909",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"TODO: change the augmentation method\"\n",
    "transform_norm = transforms.Compose([\n",
    "    lambda x: Image.fromarray(x),\n",
    "    transforms.Resize([28,28]),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize([0.5],[0.5]),\n",
    "    transforms.Normalize([mean_train/255], [std_train/255])\n",
    "])\n",
    "#transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              #transforms.Normalize((0.5,), (0.5,)),])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a38b598",
   "metadata": {},
   "source": [
    "##### 1.3 First, check the documentation of dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70088afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainloader = torch.utils.data.DataLoader(trainset0, batch_size=batch_size_train, shuffle=True)\n",
    "# testloader = torch.utils.data.DataLoader(testset0, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83216958",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dee6517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset = EmnistDataset(train_x, train_y)\n",
    "# testset = EmnistDataset(test_x, test_y)\n",
    "trainset = EquationDataset(train_x, train_y, transform = transform_norm)\n",
    "testset = EquationDataset(test_x, test_y, transform = transform_norm)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size_train, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size_test, shuffle=False)\n",
    "# print(trainset.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4e99d6-6478-4496-8528-18042c4aacc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fcda99c",
   "metadata": {},
   "source": [
    "##### 2 Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ce69131",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "        # self.conv2_drop = nn.Dropout2d()\n",
    "        \n",
    "        self.fc1 = nn.Linear(32*7*7, 10)\n",
    "        #self.fc2 = nn.Linear(50, 10) # TODO change label+1\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"feature\" , x.shape)\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        #x = self.fc2(x)\n",
    "        return F.log_softmax(x, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a503bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Read the documentation of torchvision.models to try more cnn models\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be229a",
   "metadata": {},
   "source": [
    "##### 3 Write the training function and the testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4b55b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    # evaluation, freeze \n",
    "    model.eval()\n",
    "    total_num = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for _, (data, target) in enumerate(test_loader):\n",
    "            \n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            predict_one_hot = model(data)\n",
    "            #print(predict_one_hot)\n",
    "            _, predict_label = torch.max(predict_one_hot, 1)\n",
    "            #print(\"label\", predict_label, \"target\", target)\n",
    "            total_correct += (predict_label == target).sum().item()\n",
    "            total_num += target.size(0)\n",
    "            if total_num == 100:\n",
    "                with open('predict_label.txt', 'w') as f:\n",
    "                    for i in range(100):\n",
    "                        if data_list_test[i].endswith(\".png\"):\n",
    "                        \n",
    "                            f.write(data_list_test[i]+' ')\n",
    "                            f.write(str(predict_label.numpy()[i]))\n",
    "                            f.write('\\n')\n",
    "                        #print(data_list_test[i], predict_label.numpy()[i])\n",
    "            #print ('total_num', total_num)\n",
    "        \n",
    "    return (total_correct / total_num)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681307a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, num_epoch, learning_rate, momentum, device):\n",
    "    train_losses = []\n",
    "    \n",
    "    # 1, define optimizer\n",
    "    \n",
    "    \"TODO: try different optimizer\"\n",
    "    \n",
    "    \n",
    "    # optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "    #                   momentum=momentum)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=learning_rate)\n",
    "\n",
    "    \n",
    "    for epoch in tqdm(range(num_epoch)):\n",
    "        # train the model\n",
    "        model.train()\n",
    "        \n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            \n",
    "            data = data.to(device)\n",
    "            # print('*****', data.shape)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 2, forward\n",
    "            output = network(data)\n",
    "            #print('output', output)\n",
    "            \n",
    "            # 3, calculate the loss\n",
    "            \n",
    "                    \n",
    "            \"TODO: try use cross entropy loss instead \"\n",
    "            \n",
    "            loss = F.nll_loss(output, target)\n",
    "            \n",
    "            #loss = nn.CrossEntropyLoss()\n",
    "            #input = torch.randn(3, 10, requires_grad=True)\n",
    "            #target = torch.empty(3, dtype=torch.long).random_(10)\n",
    "            #output = loss(input, target)\n",
    "            #output.backward()\n",
    "            \n",
    "            # 4, backward\n",
    "            loss.backward()\n",
    "            \n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "        # evaluate the accuracy on test data for each epoch\n",
    "        accuracy_train = test(model, train_loader, device)\n",
    "        accuracy_test = test(model, test_loader, device)\n",
    "        with open('result.txt', 'a') as f:\n",
    "            f.write('accuracy_train'+str(accuracy_train))\n",
    "            f.write('\\n')\n",
    "            f.write('accuracy_test'+str(accuracy_test))\n",
    "            f.write('\\n')\n",
    "        #print('accuracy_train', accuracy_train)\n",
    "        #print('accuracy_test', accuracy_test)\n",
    "        \n",
    "    # 5, save model\n",
    "    \n",
    "    \"TODO: change the number of epochs save the model with the best prediction accuracy\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e854b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device0 = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# use cpu if you do not have gpu installed in your computer\n",
    "network = Net().to(device0)\n",
    "train(model=network, train_loader=trainloader, test_loader=testloader, num_epoch=n_epochs, learning_rate=learning_rate, momentum=momentum, device=device0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53931d5b-a30d-4a48-8036-ca0cea066087",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), 'final.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3689db70-3159-414b-a56e-fa96ac0c1fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device0 = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# use cpu if you do not have gpu installed in your computer\n",
    "network = Net().to(device0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a06b3d0",
   "metadata": {},
   "source": [
    "#### 4 Calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90669233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TODO: load your saved model and calculated the accuracy, you can use the test function provided above'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"TODO: load your saved model and calculated the accuracy, you can use the test function provided above\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8040b9ca-4961-45c6-bc92-50de6566ce46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_test 0.95\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load('final.pth'))\n",
    "model.eval()\n",
    "accuracy_test = test(model, testloader, device=device0)\n",
    "print('accuracy_test', accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1293290-34b6-45a8-9649-95e529697fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3c3f3-8d57-42df-a451-68020ae0f1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
